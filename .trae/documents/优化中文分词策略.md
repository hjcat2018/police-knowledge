## 中文分词优化方案

### 问题分析
当前使用的滑动窗口n-gram分词产生无意义结果（如"殴打他"、"人的处"），严重影响搜索质量。

### 解决方案

#### 1. 添加中文分词库依赖
**修改文件**: `backend/pom.xml`

添加 ansj_seg 分词库依赖（支持Java 17）：
```xml
<dependency>
    <groupId>org.ansj</groupId>
    <artifactId>ansj_seg</artifactId>
    <version>5.1.6</version>
</dependency>
```

#### 2. 创建中文分词工具类
**新建文件**: `backend/src/main/java/com/police/kb/common/ChineseSegmenter.java`

实现基于ansj_seg的中文分词功能：
- 支持智能分词模式
- 过滤停用词（的、了、是等）
- 提取有意义的关键词

#### 3. 修改搜索逻辑
**修改文件**: `backend/src/main/java/com/police/kb/service/impl/VectorServiceImpl.java`

改进 `fullTextSearch` 方法：
- 移除现有的滑动窗口分词逻辑（行423-435）
- 使用 ChineseSegmenter 进行中文分词
- 使用分词后的关键词进行全文搜索

#### 4. 预期分词效果
输入: "殴打他人的处罚有哪些？"
输出: ["殴打", "他人", "处罚", "哪些"]

### 预期效果
- **中文分词更准确**: 使用专业分词库替代滑动窗口
- **搜索结果更相关**: 匹配有意义的中文词汇而非字符组合
- **减少噪音结果**: 过滤单字符和无意义词汇

### 文件清单
1. `backend/pom.xml` - 添加ansj_seg分词库依赖
2. `backend/src/main/java/com/police/kb/common/ChineseSegmenter.java` - 中文分词工具类（新建）
3. `backend/src/main/java/com/police/kb/service/impl/VectorServiceImpl.java` - 优化全文搜索逻辑