# 文档向量化完整工作流程

## 概述

本文档详细描述了警察知识库系统中文档向量化的完整技术流程，包括文档预处理阶段（离线批量处理）和检索阶段（实时查询）的所有技术细节。该系统采用 SeekDB 向量数据库与 BAAI/bge-m3 嵌入模型相结合的技术栈，实现了法律法规文档的语义检索能力。

## 技术栈概述

系统的核心技术栈由以下组件构成：SeekDB 作为向量数据库负责存储和检索向量数据，BAAI/bge-m3 作为文本嵌入模型将文本转换为 1024 维的语义向量，MyBatis-Plus 作为 ORM 框架管理数据库操作，Spring Boot 作为应用框架提供 RESTful API 服务。整体架构遵循 RAG（检索增强生成）模式，将向量检索与 LLM 生成能力相结合，为用户提供基于法律知识的智能问答服务。

向量检索的核心优势在于能够捕捉文本的语义相似性，而非仅仅依赖关键词匹配。例如，当用户询问"打架斗殴的处罚"时，系统不仅能匹配包含"打架斗殴"关键词的文档，还能检索到涉及"殴打他人"、"寻衅滋事"等相关法律条文的文档，大大提升了检索的召回率和准确性。

## 整体架构概览

系统采用分层架构设计，从下至上依次为：数据存储层（SeekDB 向量数据库、MySQL 元数据数据库）、向量处理层（嵌入模型服务、向量计算引擎）、业务服务层（文档向量化服务、混合检索服务、RAG 生成服务）、接口层（RESTful API、WebSocket 流式接口）。每一层都有明确的职责边界，层与层之间通过标准化接口进行通信，保证了系统的可维护性和可扩展性。

文档向量化流程分为两个相互独立但又紧密关联的主要阶段。第一阶段是文档预处理阶段，当管理员上传法律法规文档时，系统自动执行内容提取、智能分块、向量生成、数据存储等一系列操作，将文档转化为可检索的向量数据。第二阶段是检索阶段，当用户提出问题时，系统实时生成查询向量，执行混合搜索，最后将检索结果用于增强 LLM 的回答生成。

## 第一阶段：文档预处理

### 文档上传与内容提取

文档预处理的第一步是接收并解析用户上传的法律法规文档。系统通过 `DocumentController` 提供的 RESTful 接口接收文档上传请求，调用 `DocumentService` 进行文档的验证和初始化，然后将文档元数据存储到 MySQL 的 `documents` 表中。文档实体 `Document` 包含了丰富的元数据信息，这些信息对于后续的向量化处理和检索结果排序都具有重要价值。

`Document` 实体的核心字段设计如下：`id` 作为文档的唯一标识符，采用自增主键策略；`title` 存储文档标题，如《治安管理处罚法》、《刑法》等法律名称；`content` 存储文档的完整正文内容，这是向量化处理的主要输入来源；`summary` 存储文档的摘要信息，可用于快速预览和检索增强；`docType` 标识文档类型，用于区分法律、法规、规章、司法解释等不同级别的规范性文件；`kbId` 关联文档所属的知识库，支持多知识库的场景隔离；`status` 标记文档的当前状态，包括待处理、处理中、已发布、已归档等；`createdTime` 和 `updatedTime` 记录文档的时间戳信息。

内容提取的质量直接影响后续向量化效果。系统支持多种文档格式的解析，包括 PDF、Word、TXT 等常见格式。解析过程中，系统会特别关注法律条文的编号格式（如"第XXX条"）和章节结构，确保这些语义边界信息在提取过程中不被破坏。对于 PDF 文档，系统会使用专门的 PDF 解析库来提取文本内容，同时保留段落和列表的结构信息。

### 智能语义分块

智能语义分块是整个向量化流程中最关键的环节，其目标是将长文档切分为适合向量检索的文本块，同时保证每个文本块的语义完整性和相对独立性。系统通过 `VectorServiceImpl.splitByParagraph()` 方法实现分块功能，支持多种分块策略的灵活配置。

当前系统默认采用 `"smart"` 智能语义分块策略，该策略专门针对法律文档的特点进行了优化设计。法律文档的一个显著特点是具有明确的条文编号体系，每一条文通常包含一个完整的法律规则，语义相对独立。因此，智能分块策略的首要原则是确保法律条文不被切断。

智能语义分块的核心逻辑实现在 `smartSemanticSplit()` 方法中，该方法采用多级分割策略来确保分块质量。第一级分割使用法律条文编号的正则表达式 `"第[一二三四五六七八九十百千零]+条"` 识别条文边界，将文档初步划分为若干个条文单元。第二级分割在条文内部进行段落识别，以双换行符 `\n\n` 为主要分隔标志，保留自然段落的完整性。第三级分割处理超长段落，对于超过预设阈值的段落，在句子边界处进行二次切分。

分块尺寸的控制对于检索效果至关重要。系统配置的主要参数包括：`chunkSize` 设置为 512 字符，这是每个文本块的最大长度限制；`chunkOverlap` 设置为 150 字符，表示相邻文本块之间需要保留的重叠区域。重叠区域的设计目的是确保跨块的信息不会丢失，例如一个法律条文的前半部分在某一块中提及某概念，而后半部分对其进行详细解释，这两个块之间需要有足够的重叠来保持语义的连续性。

智能合并与拆分机制是分块策略的另一重要组成部分。对于过短的文本块（长度小于 200 字符），系统会将其与相邻的文本块进行合并，以避免产生过多琐碎的向量导致检索精度下降。反之，对于过长的文本块（长度超过 800 字符），系统会在句子边界处进行二次切分，句子边界的识别使用中文标点符号（句号、问号、叹号、分号）作为标志。切分完成后，系统还会进行最后的合并检查，将连续的小块合并为中等大小的块，以优化检索效率。

### 批量向量生成

分块完成后，系统需要将每个文本块转换为高维向量表示。这一过程通过 `VectorServiceImpl.generateVectors()` 方法实现，调用外部嵌入模型服务生成向量。嵌入模型的选择直接影响向量的语义表达能力，系统经过评估后选用 BAAI/bge-m3 模型作为默认的嵌入模型。

BAAI/bge-m3 是北京智源人工智能研究院开发的第三代语义嵌入模型，具有以下技术特点：首先，它支持多语言文本的嵌入处理，不仅能够处理中文文本，还能兼容英文法律术语的嵌入；其次，它生成的向量维度为 1024 维，在保持向量表达能力的同时控制了存储和计算成本；再次，它在中文语义理解任务上表现优异，特别是在法律、医疗等专业领域的文本相似度计算上有较高的准确性。

向量生成的 API 调用采用 HTTP REST 形式，嵌入服务的 URL 和模型名称通过 `SeekDBConfig` 配置类进行管理。请求体的构建使用 `EmbeddingRequest` 对象，将待嵌入的文本列表作为输入。系统支持批量嵌入请求，多个文本块可以合并在单次 API 调用中进行处理，这样可以显著减少网络开销和 API 调用次数，提升大规模文档处理的效率。

向量生成过程中需要处理多种异常情况。系统实现了完善的重试机制，当嵌入服务暂时不可用或返回错误时，会自动进行最多 3 次重试，每次重试之间设置适当的退避间隔。对于持续失败的请求，系统会记录错误日志，但不会中断整体的文档处理流程，确保单个文档的处理失败不会影响其他文档的处理。

嵌入结果的解析同样需要谨慎处理。嵌入服务返回的结果中包含每个输入文本对应的向量数据，系统需要将这些向量数据转换为 `List<Float>` 格式以便后续存储和计算。向量数据在数据库中以 JSON 格式存储，这样设计既保证了跨平台的兼容性，又便于调试和数据分析。

### 向量数据存储

生成的向量数据需要持久化存储到 SeekDB 向量数据库中。系统通过 `VectorServiceImpl.batchInsertVectors()` 方法实现批量插入功能，将向量数据与原始文本块、元数据信息一起存储到 `document_vectors` 表中。

`DocumentVector` 实体是向量数据存储的核心载体，其表结构设计如下：`id` 是向量记录的唯一标识符，采用自增主键策略；`documentId` 关联原始文档的 ID，建立向量与源文档之间的关联关系；`content` 存储分块后的文本内容，这是检索结果展示的主要依据；`vector` 字段以 JSON 格式存储 1024 维的向量数据；`metadata` 字段同样以 JSON 格式存储元数据信息，包括 chunkIndex（该块在原文档中的序号）、chunkStart（起始位置）、chunkEnd（结束位置）等信息；`createdTime` 记录向量创建时间；`deleted` 是软删除标记，支持数据的逻辑删除和恢复。

向量索引的设计对于检索性能至关重要。系统采用 HNSW（Hierarchical Navigable Small World）算法构建向量索引，这是一种高效的近似最近邻搜索算法，特别适合高维向量的快速检索。HNSW 索引的关键参数配置如下：`M` 设置为 16，控制图中每个节点的连接数量；`efConstruction` 设置为 200，控制索引构建时的搜索广度；`efSearch` 设置为 100，控制检索时的搜索深度。这些参数在 `SeekDBConfig` 配置类中进行集中管理，可以根据实际硬件条件和性能需求进行调整。

HNSW 索引相比传统的 IVF 索引具有以下优势：查询时间复杂度更低，通常能在毫秒级时间内完成大规模向量的检索；索引构建速度更快，支持在线增量更新；检索精度更高，在相同的召回率要求下需要的搜索范围更小。系统选择 HNSW 索引正是基于这些技术优势的考量。

批量插入操作采用事务管理，确保数据的一致性。当插入失败时，系统会回滚事务并记录错误信息。插入完成后，系统还会进行数据校验，确认插入的向量数量与分块数量一致，防止数据丢失。

## 第二阶段：检索阶段

### 查询向量生成

当用户提出问题时，系统首先需要将问题文本转换为查询向量。查询向量的生成与文档向量化使用相同的嵌入模型和配置，确保查询与文档处于同一个语义向量空间。这是实现语义检索的技术基础。

查询向量生成调用 `generateVectors(String query)` 方法，输入是用户的自然语言问题，如"打架斗殴怎么处罚"、"盗窃罪判几年"等。输出是 1024 维的浮点数向量，该向量编码了问题的语义信息。值得注意的是，查询向量的生成需要考虑问题的长度和结构，对于过短的问题（如单个词语），系统会进行适当的扩展以提升语义表达的准确性。

向量空间的对齐是语义检索的关键技术点。理论上，如果查询和文档使用相同的嵌入模型，它们应该处于同一个向量空间，语义相近的文本在向量空间中距离更近。但实践中，由于训练数据的差异或模型版本的变化，可能会出现向量空间不完全对齐的情况。系统通过定期的向量空间测试来监控这种情况，必要时可以触发文档的重新向量化。

### 混合搜索策略

查询向量生成后，系统执行混合搜索策略，同时进行向量相似度搜索和全文搜索两种检索方式，然后通过加权融合得到最终的综合得分。这种策略结合了两种检索方式的优点，既能捕捉语义相似性，又能确保关键词的精确匹配。

向量相似度搜索基于向量空间的距离计算。系统使用 L2 距离（欧几里得距离）作为相似度度量，距离越小表示向量越相似。对于给定的查询向量，系统遍历 `document_vectors` 表中的所有向量记录，计算查询向量与每个文档向量的 L2 距离，然后按距离升序排列，取距离最小的 TopK 条记录作为向量搜索结果。

全文搜索采用传统的 SQL LIKE 查询，匹配问题文本中的关键词在文档内容中的出现情况。这种检索方式的优势在于能够精确匹配用户使用的具体词汇，对于专有名词、法律术语等具有较高的检索精度。但全文搜索的局限性在于无法处理同义词和语义关联，例如用户使用"殴打"一词时，可能无法匹配到使用"打人"表述的相关法律条文。

系统通过 `seekDBHybridSearch()` 方法实现混合搜索功能。该方法首先并行执行向量搜索和全文搜索，然后对两种搜索的结果进行加权融合。融合公式为：`综合分数 = 0.6 × 归一化向量相似度分数 + 0.4 × 归一化全文匹配分数`。向量搜索权重设为 0.6，全文搜索权重设为 0.4，这个配比是基于大量实验调优得到的经验值，在大多数法律问答场景下表现良好。

归一化处理是融合前的重要步骤。由于向量搜索和全文搜索使用的评分体系不同，直接相加没有意义。系统将两种搜索的得分分别归一化到 0-1 区间，然后再进行加权融合。向量搜索使用 1 / (1 + L2距离) 作为相似度得分，全文搜索使用关键词匹配密度作为得分，两者通过 min-max 归一化处理后进行融合。

### 结果过滤与排序

混合搜索得到的结果需要经过过滤和排序才能返回给用户。系统根据配置参数进行多级过滤，确保返回的检索结果既相关又有足够的数量。

第一级过滤是相似度阈值过滤。系统配置 `similarityThreshold = 0.3` 作为相似度阈值，只有综合得分大于等于该阈值的结果才会被保留。这个阈值经过实际测试调优，设置为 0.3 时能够在保证相关性的前提下最大化召回率。如果阈值设置过高（如之前的 0.7），可能会遗漏重要的相关文档；如果阈值设置过低（如 0.1），可能会引入过多不相关的结果。

第二级过滤是知识库范围过滤。系统支持多知识库的场景，用户可以选择在特定知识库中进行检索，也可以选择检索全部知识库。当指定知识库 ID（kbId）时，检索结果只返回该知识库中的文档向量；当 kbId 为空或小于等于 0 时，检索所有知识库的文档。

第三级过滤是 TopK 数量限制。系统配置 `topK = 10`，限制返回的检索结果数量最多为 10 条。这个数量经过评估，既能保证检索结果的多样性，又不会因为结果过多而影响后续的 LLM 生成质量。对于某些复杂问题，可能需要返回更多的上下文信息，此时可以通过调整 topK 参数来扩展结果数量。

排序策略采用综合得分降序排列，将语义相似度最高、关键词匹配度最高的结果排在前面。排序后的结果封装在 `SearchResult` 对象中，包含文档 ID、标题、内容、相似度分数等关键信息，供后续的 RAG 服务使用。

## 流程图总结

```
┌─────────────────────────────────────────────────────────────────┐
│                      文档向量化完整流程                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  【文档预处理阶段】                                               │
│                                                                 │
│  文档上传 ──→ 内容提取 ──→ 智能语义分块 ──→ 批量生成向量 ──→ 存储  │
│    │              │              │              │            │   │
│  Document    title/content   512字符    BAAI/bge-m3   document_  │
│  实体       summary        重叠150     1024维       vectors表   │
│                 │              │              │                 │
│            kbId/docType    智能条文    重试机制     HNSW索引     │
│                              识别                    (M=16)     │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  【检索查询阶段】                                                 │
│                                                                 │
│  用户提问 ──→ 生成查询向量 ──→ 混合搜索 ──→ 加权融合 ──→ 结果过滤  │
│    │              │              │            │            │   │
│  "打架斗殴    BAAI/bge-m3   向量+L2   0.6×向量   TopK=10,    │
│   的处罚？"   1024维      全文LIKE  +0.4×全文   阈值≥0.3    │
│                 │              │            │                 │
│              语义编码    双轨并行    综合得分    知识库过滤    │
│                           检索                      (kbId)     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## 关键配置参数

系统的行为通过 `SeekDBConfig` 配置类进行集中管理，核心配置参数及其说明如下表所示：

| 参数名称 | 当前值 | 参数说明 |
|---------|--------|---------|
| chunkSize | 512 | 智能分块时每个文本块的最大字符数，过大的值可能导致向量语义过于宽泛，过小的值可能丢失上下文信息 |
| chunkOverlap | 150 | 相邻文本块之间的重叠字符数，用于保持跨块语义的连续性，值越大检索越稳定但存储开销越高 |
| embeddingModel | BAAI/bge-m3 | 嵌入模型名称，支持切换为其他兼容的嵌入模型，如 BGE、SGPT 等 |
| vectorDimension | 1024 | 向量维度，由嵌入模型决定，BAAI/bge-m3 固定输出 1024 维向量 |
| topK | 10 | 检索阶段返回的最大结果数量，建议值 5-20，根据实际性能需求调整 |
| similarityThreshold | 0.3 | 相似度阈值过滤，只有综合得分 >= 0.3 的结果才会被返回，过高会降低召回率，过低会引入噪声 |
| enableReranker | false | 重排序开关，启用后可在向量检索后增加重排序模型进一步优化结果顺序 |
| vectorWeight | 0.6 | 混合搜索中向量检索的权重系数，建议值 0.5-0.7 |
| fulltextWeight | 0.4 | 混合搜索中全文检索的权重系数，与 vectorWeight 之和应等于 1.0 |
| hnswM | 16 | HNSW 索引的连接数参数，影响索引的精度和构建时间 |
| hnswEfConstruction | 200 | HNSW 索引构建时的搜索广度，值越大索引质量越高但构建越慢 |
| hnswEfSearch | 100 | HNSW 检索时的搜索深度，值越大检索精度越高但响应越慢 |

## 文件位置索引

以下列出文档向量化流程涉及的核心源代码文件及其位置，便于开发人员快速定位和理解代码：

| 文件路径 | 功能说明 |
|---------|---------|
| [VectorServiceImpl.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/service/impl/VectorServiceImpl.java) | 向量化服务核心实现，包含分块、向量生成、混合搜索等关键方法 |
| [SeekDBConfig.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/config/SeekDBConfig.java) | SeekDB 和 RAG 配置类，包含所有可调整的系统参数 |
| [DocumentVector.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/entity/DocumentVector.java) | 向量数据实体类，定义 document_vectors 表的数据结构 |
| [Document.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/entity/Document.java) | 文档实体类，定义 documents 表的数据结构 |
| [RagServiceImpl.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/service/impl/RagServiceImpl.java) | RAG 服务实现，调用向量检索并生成最终回答 |
| [StreamChatController.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/controller/StreamChatController.java) | 流式问答接口控制器，处理用户的智能问答请求 |
| [DocumentController.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/controller/DocumentController.java) | 文档管理接口控制器，处理文档上传和管理请求 |
| [DocumentVectorMapper.java](file:///d:/study/test9-3/backend/src/main/java/com/police/kb/repository/DocumentVectorMapper.java) | 向量数据访问层，提供数据库操作接口 |

## 常见问题与解决方案

在文档向量化流程的运行过程中，可能会遇到以下常见问题：

**问题一：检索结果不完整**。如果发现某些应该被检索到的法律条文没有出现在结果中，首先应该检查相似度阈值是否设置过高。系统当前阈值设置为 0.3，如果阈值高于 0.5 可能会过滤掉部分相关结果。其次应该检查知识库过滤设置，确认目标知识库已被正确关联到文档。

**问题二：检索速度变慢**。检索速度下降通常与向量数据量增长有关。当 `document_vectors` 表中的记录数超过一定规模后，需要考虑优化 HNSW 索引参数或增加索引重建频率。可以通过监控查询响应时间来评估索引性能，必要时执行 `optimize_vector_index.sql` 脚本进行索引优化。

**问题三：向量生成失败**。向量生成失败可能是由于嵌入服务不可访问或请求频率超限。系统内置了重试机制和错误日志记录，可以通过查看 `backend.log` 中的错误信息来定位具体原因。如果问题持续存在，需要检查嵌入服务的可用性和网络连接。

**问题四：文档分块质量不佳**。如果发现某些法律条文被错误地切割成多个部分，或相邻条文被错误合并，可能需要调整分块参数或优化分块逻辑。可以通过修改 `chunkSize`、`chunkOverlap` 参数或调整条文识别正则表达式来改善分块质量。

## 性能优化建议

针对大规模文档向量化场景，提出以下性能优化建议：

批量处理优化方面，建议使用系统提供的批量处理接口进行大规模文档的向量化，避免单条处理的额外开销。可以通过调整 `BatchProcessingConfig` 中的批处理大小参数来平衡处理速度和内存占用。

索引优化方面，HNSW 索引的构建参数需要在索引质量和构建速度之间取得平衡。对于写入密集型场景，可以适当降低 `hnswEfConstruction` 参数的值以加快索引构建；对于查询密集型场景，可以增加 `hnswEfSearch` 参数的值以提升查询精度。

缓存优化方面，可以考虑在检索路径上增加查询结果缓存，对于相同或相似的问题直接返回缓存结果。这需要在 `RagService` 层实现缓存逻辑，并设计合理的缓存过期策略。

硬件优化方面，向量数据库的性能与硬件配置密切相关。建议使用 SSD 存储以提升随机读写性能，确保有足够的内存来缓存热点向量数据，并根据数据规模选择合适的 CPU 配置以支持并行计算。

## 版本信息

文档版本：1.0  
创建日期：2026年1月27日  
适用版本：police-kb-system v1.0 及以上  
维护人员：系统开发团队
